{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem  : Identify the Digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set seed \n",
    "np.random.seed(101)\n",
    "tf.set_random_seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_path = \"datasets/av_mnist_data/\"\n",
    "train_path = \"datasets/av_mnist_data/mnist_av_images/train/\"\n",
    "test_path = \"datasets/av_mnist_data/mnist_av_images/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(train_labels_path+'mnist_av_train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading train data\n",
    "x_train_lst,y_train_lst = [],[]\n",
    "_ = [(x_train_lst.append(cv2.imread(train_path+file,cv2.IMREAD_GRAYSCALE)),y_train_lst.append(labels.loc[labels.filename == file,'label'].values)) for file in os.listdir(train_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading test data\n",
    "x_test_lst = []\n",
    "_ = [x_test_lst.append(cv2.imread(test_path+file,cv2.IMREAD_GRAYSCALE)) for file in os.listdir(test_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to numpy array\n",
    "x_train_org = np.array(x_train_lst)\n",
    "y_train_org = np.squeeze(y_train_lst)\n",
    "x_test_org = np.array(x_test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the shape\n",
    "print(\"x train shape:\",x_train_org.shape)\n",
    "print(\"y train shape:\",y_train_org.shape)\n",
    "print(\"x test shape:\",x_test_org.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the image\n",
    "index = 1\n",
    "print(\"Image has digit:\",y_train_org[index])\n",
    "plt.imshow(x_train_org[index,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize data\n",
    "x_train = x_train_org/255.0\n",
    "x_test = x_test_org/255.0\n",
    "\n",
    "## convert it into categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the shape\n",
    "print(\"x train shape:\",x_train.shape)\n",
    "print(\"y train shape:\",y_train.shape)\n",
    "print(\"x test shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reshape the data\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the shape\n",
    "print(\"x train shape:\",x_train.shape)\n",
    "print(\"y train shape:\",y_train.shape)\n",
    "print(\"x test shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data as numpy object\n",
    "# np.save('x_train.npy',x_train)\n",
    "# np.save('x_test.npy',x_test)\n",
    "# np.save('y_train.npy',y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the npy objects data\n",
    "# x_train = np.load('./data/x_train.npy',mmap_mode='r+')\n",
    "# y_train = np.load('./data/y_train.npy',mmap_mode='r+')\n",
    "# x_test = np.load('./data/x_test.npy',mmap_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the shape\n",
    "print(\"x train shape:\",x_train.shape)\n",
    "print(\"y train shape:\",y_train.shape)\n",
    "print(\"x test shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr = .005,decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=128,epochs=150,validation_split=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## See the cross validation vs taining loss\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set accuracy :\",model.evaluate(x_train,y_train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "# model.save('./av_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load model\n",
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model('av_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate prediction for test data\n",
    "pred_dict = {}\n",
    "output = []\n",
    "\n",
    "for file in os.listdir(test_path):\n",
    "    pred_dict['filename'] = file\n",
    "    img = cv2.imread(test_path+file,cv2.IMREAD_GRAYSCALE)\n",
    "    img = img.reshape(1,img.shape[0],img.shape[1],1)\n",
    "    img = img/255.0\n",
    "    pred_dict['label'] = np.squeeze(model.predict_classes(img))\n",
    "    output.append(pred_dict)\n",
    "    pred_dict = {}\n",
    "\n",
    "df = pd.DataFrame(output)\n",
    "df.to_csv('./solution.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Results \n",
    "\n",
    "** Train data accuracy:** 99.77%   \n",
    "** Test data accuracy:** 99.428%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
